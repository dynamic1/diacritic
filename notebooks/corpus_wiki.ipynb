{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "\n",
    "# import xml.etree.ElementTree as etree\n",
    "\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "# from gensim.models.word2vec import word2vec\n",
    "\n",
    "\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the variable names at the end of a cell ( not just the last one)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use(\"TkAgg\")\n",
    "%matplotlib inline\n",
    "\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/xalex/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a corpus of Romanian words from Romanian wikipedia dump.\n",
    "The dump is already parsed using https://github.com/attardi/wikiextractor ( with some customc changes ) and dumped in files of apporx 1M in size in folders of 100 files max.\n",
    "\n",
    "Steps:\n",
    "1. read all input files ( generated by WikiExtractorX from wiki dumps) \n",
    "2. do some cleaning\n",
    "3. build list of words with counters \n",
    "\n",
    "Text files are in \"../data/text/[A-Z][A-Z]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "TEXT_FILES_PATH = join(DATA_PATH, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files to process: 370\n"
     ]
    }
   ],
   "source": [
    "number_of_files = 0\n",
    "for (root_dir, dirs, files) in walk(TEXT_FILES_PATH):\n",
    "    number_of_files += len(files)\n",
    "print(f\"number of files to process: {number_of_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nword_counter = Counter()\\nword_counter_lower = Counter()\\nfiles_to_process = []\\n\\nfiles_counter = 0\\nfor (root_dir, dirs, files) in walk(TEXT_FILES_PATH):\\n    files_counter += len(files)\\n\\nfiles_counter = 0\\nfor (root_dir, dirs, files)  in walk(TEXT_FILES_PATH):\\n    for local_file_name in files:\\n        files_counter += 1 \\n        local_file_path = join(root_dir, local_file_name)\\n        if isfile(local_file_path):\\n            files_to_process.append(local_file_path)\\n            \\nbar = progressbar.ProgressBar()\\nfor local_file_path in bar(files_to_process):\\n    with open(local_file_path, \\'r\\', encoding=\\'utf8\\') as text_file:\\n        for word in text_to_word_sequence(text_file.read(), \\n                                            filters=\\'!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n\\',\\n                                            lower=True):\\n            word_counter_lower[word] += 1\\n    # case insensitive\\n    with open(local_file_path, \\'r\\', encoding=\\'utf8\\') as text_file:\\n        for word in text_to_word_sequence(text_file.read(), \\n                                            filters=\\'!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n\\',\\n                                            lower=False):\\n            word_counter[word] += 1\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "word_counter = Counter()\n",
    "word_counter_lower = Counter()\n",
    "files_to_process = []\n",
    "\n",
    "files_counter = 0\n",
    "for (root_dir, dirs, files) in walk(TEXT_FILES_PATH):\n",
    "    files_counter += len(files)\n",
    "\n",
    "files_counter = 0\n",
    "for (root_dir, dirs, files)  in walk(TEXT_FILES_PATH):\n",
    "    for local_file_name in files:\n",
    "        files_counter += 1 \n",
    "        local_file_path = join(root_dir, local_file_name)\n",
    "        if isfile(local_file_path):\n",
    "            files_to_process.append(local_file_path)\n",
    "            \n",
    "bar = progressbar.ProgressBar()\n",
    "for local_file_path in bar(files_to_process):\n",
    "    with open(local_file_path, 'r', encoding='utf8') as text_file:\n",
    "        for word in text_to_word_sequence(text_file.read(), \n",
    "                                            filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                            lower=True):\n",
    "            word_counter_lower[word] += 1\n",
    "    # case insensitive\n",
    "    with open(local_file_path, 'r', encoding='utf8') as text_file:\n",
    "        for word in text_to_word_sequence(text_file.read(), \n",
    "                                            filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                            lower=False):\n",
    "            word_counter[word] += 1\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asd fghj rty r'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['„', '„', '<']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'greață sau diaree recomandată'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'URL\\n\\nURL\\n\\nURL\\n\\nURL\\n\\nURL\\n\\nURL\\n\\nURL\\n\\nURL'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re_strip = re.compile(\"[„” <>–«»;//“’'_\\\"]\")\n",
    "\n",
    "\n",
    "re_strip.sub(' ', \"asd„fghj„rty<r\")\n",
    "\n",
    "res = re_strip.findall(\"asd„fghj„rty<r\")\n",
    "res\n",
    "\n",
    "'greață\\xa0sau\\xa0diaree\\xa0recomandată'.replace(u'\\xa0', ' ')\n",
    "\n",
    "\n",
    "\n",
    "t = \"\"\"http://www.agenda.ro/eugen-cuteanu-un-nume-ce-nu-poate-fi-despartit-de-viata-muzicala-banateana/1196\n",
    "\n",
    "http://www.discogs.com/artist/Ioan+Fernbach\n",
    "\n",
    "http://www.viata-medicala.ro/*articleID_6531-dArt.html\n",
    "\n",
    "http://www.ceeol.com/aspx/issuedetails.aspx?issueid=7099f7b2-772f-4101-ac55-1ea9c8eb9031&articleId=807e8a2a-0af2-4cfe-8b7e-7a89835cd726\n",
    "\n",
    "http://connection.ebscohost.com/c/articles/84312225/internetul-ca-mijloc-integrat-n-studiul-viorii\n",
    "\n",
    "http://www.romanialibera.ro/actualitate/locale/turneele-filarmonicii-banatul-o-solie-de-exceptie-in-strainatate-34902.html\n",
    "\n",
    "http://www.adevarul.ro/locale/timisoara/portret-ioan-fernbach-germanul-aflat-36-ani--slujba-muzicii-1_50bd52687c42d5a663ca5c19/index.html\n",
    "\n",
    "http://www.crispedia.ro/Wilhem_Georg_Berger\"\"\"\n",
    "\n",
    "m = re_url.findall(t)\n",
    "\n",
    "re_url.sub('URL', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/xalex/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata as UD\n",
    "    \n",
    "# TEXT_FILES_PATH = \"../data/text\"\n",
    "word_counter = Counter()\n",
    "word_counter_lower = Counter()\n",
    "files_to_process = []\n",
    "\n",
    "# build a list of all files to process\n",
    "files_counter = 0\n",
    "for (root_dir, dirs, files)  in walk(TEXT_FILES_PATH):\n",
    "    for local_file_name in files:\n",
    "        files_counter += 1 \n",
    "        local_file_path = join(root_dir, local_file_name)\n",
    "        if isfile(local_file_path):\n",
    "            files_to_process.append(local_file_path)\n",
    "            \n",
    "\n",
    "# use this re to check if paragraphs use propper spelling\n",
    "re_contains_diacriticals = re.compile('[ÎĂȘȚîășțîâ]')\n",
    "# the \"space\" in re_contains_weird_chars is not regular 'space', but '\\xa0' - non braking space\n",
    "re_contains_weird_chars = re.compile('[^a-zA-Z0-9,.?! ÎĂȘȚîășțîâ\\:\\-\\(\\)]')\n",
    "# find URLs\n",
    "re_url = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "#these chars will be stripped from text\n",
    "re_strip = re.compile(\"[„”<>–«»;//“’'_\\\"]\")\n",
    "\n",
    "#re_contains_right_to_left = re.compile('\\u200f')\n",
    "counter_weird_chars = Counter()\n",
    "\n",
    "count_sentences_no_diacriticals = 0\n",
    "count_sentences = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (370 of 370) |#######################| Elapsed Time: 0:05:17 Time: 0:05:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentences: 2988867\n",
      "sentences without diacriticals: 318912\n"
     ]
    }
   ],
   "source": [
    "def process_file(file_path):\n",
    "    \n",
    "    global count_sentences_no_diacriticals \n",
    "    global count_sentences\n",
    "    global sentences_file\n",
    "    global sentences_skipped_file\n",
    "\n",
    "    with open(local_file_path, 'r', encoding='utf8') as text_file:\n",
    "        lines = text_file.readlines()\n",
    "        \n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        sentences.extend(sent_tokenize(re_url.sub('',line)))\n",
    "        \n",
    "#     print(sentences)\n",
    "    sentences = [re_strip.sub('',x.strip()).replace(u'\\xa0', ' ') for x in sentences]\n",
    "    for sentence in sentences:\n",
    "        count_sentences += 1\n",
    "        skip = False\n",
    "#         print(f\"--{sentence}--\")\n",
    "        for l in sentence:\n",
    "#             if UD.bidirectional(l) not in ['L', 'CS', 'EN','ES','ON','ET','WS','R','AL']:\n",
    "            # skip sentences with RIGHT-TO-LEFT characters\n",
    "            if UD.bidirectional(l) not in ['L', 'CS', 'EN','ES','ON','ET','WS']:\n",
    "                skip = True\n",
    "#                 print(f\"->{l}<- {ord(l)} {UD.bidirectional(l)}\")\n",
    "        \n",
    "        if not re_contains_diacriticals.search(sentence):\n",
    "            count_sentences_no_diacriticals += 1\n",
    "#             skip = True\n",
    "\n",
    "        if False:\n",
    "            res = re_contains_weird_chars.findall(sentence)\n",
    "            for c in res:\n",
    "    #            print(f\"<{c}>, ascii={ord(c)}\")\n",
    "                counter_weird_chars[c] +=1\n",
    "    #             print(sentence, end=\"\\n---------\\n\")\n",
    "                #skip = True\n",
    "            \n",
    "        if skip:\n",
    "            sentences_skipped_file.write(sentence+\"\\n\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            sentences_file.write(sentence+\"\\n\\n\")\n",
    "            # case sensitive list of words\n",
    "            for word in text_to_word_sequence(sentence, \n",
    "                                        filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                        lower=True):\n",
    "                word_counter_lower[word] += 1\n",
    "            # case insensitive list of words\n",
    "            for word in text_to_word_sequence(sentence, \n",
    "                                        filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                        lower=False):\n",
    "                word_counter[word] += 1\n",
    "                \n",
    "counter_weird_chars = Counter()\n",
    "count_sentences_no_diacriticals = 0\n",
    "count_sentences = 0\n",
    "\n",
    "#process the files and show a progress bar\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "sentences_file = open(\"../data/sentences\", \"w\", encoding='utf8')\n",
    "sentences_skipped_file = open(\"../data/sentences_skipped\", \"w\", encoding='utf8')\n",
    "\n",
    "# files_to_process = [join('/Users/alexlfll/Documents/projects.nosync/diacritic/data/text/','AC/wiki_80')]\n",
    "for local_file_path in bar(files_to_process):\n",
    "#     print(local_file_path)\n",
    "    process_file(local_file_path)\n",
    "    \n",
    "sentences_file.close()\n",
    "sentences_skipped_file.close()\n",
    "for c in counter_weird_chars:\n",
    "    print(f\"<{c}> -> {counter_weird_chars[c]} {ord(c)}\")\n",
    "\n",
    "print(f\"total sentences: {count_sentences}\")\n",
    "print(f\"sentences without diacriticals: {count_sentences_no_diacriticals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1187807 case sensitive words\n",
      "1062824 case INsensitive words\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(word_counter)} case sensitive words\")\n",
    "print(f\"{len(word_counter_lower)} case INsensitive words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688\n",
      "['aaronsohniaabrotanellaacamptopappusacanthocephalusacanthocladiumacanthodesmosacantholepisacanthospermumacanthostylesachilleaachnophoraachnopogonachyrachaenaachyroclineachyropappusachyrothalamusacilepidopsisacilepisacmellaacomisacourtiaacrisioneacritopappusacroptilonactinoboleactinoserisactitesadelostigmaadenanthellumadenocaulonadenocritoniaadenoglossaadenoonadenopappusadenophyllumadenostemmaadenostylesadenothamnusaedesiaaegopordonaequatoriumaetheolaenaaetheorhizaageratellaageratinaageratinastrumageratumagoserisagrianthusainsliaeaajaniaajaniopsisalatosetaalbertiniaalcantaraalciopealdamaalepidoclinealfrediaaliellaallagopappusallardiaalloispermumallopterigeronalmutasteralomiaalomiellaalvordiaamauriaamberboaamblyocarpumamblyolepisamblyopappusamboroaambrosiaameghinoaamellusammobiumamoliniaampelasteramphiachyrisamphiglossaamphipappusamphoricarposanacanthaanacyclusanaphalioidesanaphalisanaxetonancathiaancistrocarphusancistrophoraandryalaangelphytumangianthusanisochaetaanisocomaanisopappusanisothrixantennariaanthemisantilliaantiphionaantithrixiaanuraanvilleaapalochlamysaphanactisaphanostephusaphyllocladusapodocephalaapopyrosaposerisapostatesarbelaezasterarchibaccharisarctiumarctogeronarctothecaarctotisargyranthemumargyroglottisargyrovernoniaargyroxiphiumaristeguietiaarnaldoaarnicaarnicastrumarnoglossumarnoserisarrhenechthitesarrojadocharisarrowsmithiaartemisiaartemisiopsisasaemiaasanthusascidiogyneaspiliaasplundianthusasterasterideaasteriscusasteromoeaasteropsisasterothamnusastranthiumathanasiaathrixiaathroismaatractylisatractylodesatrichanthaatrichoserisaustrobrickelliaaustrocritoniaaustroeupatoriumaustrosynotisaxiniphyllumayapanaayapanopsisaylacophoraayniaaztecaster']\n"
     ]
    }
   ],
   "source": [
    "print(max([len(word) for word, count in word_counter_lower.items()]))\n",
    "print([word for word, count in word_counter_lower.items() if len(word)>1600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1132 \n",
      "2: 3709 \n",
      "3: 16188 \n",
      "4: 44637 \n",
      "5: 87426 \n",
      "6: 116522 \n",
      "7: 138405 \n",
      "8: 142549 \n",
      "9: 138354 \n",
      "10: 105349 \n",
      "11: 78264 \n",
      "12: 58036 \n",
      "13: 39805 \n",
      "14: 26894 \n",
      "15: 18958 \n",
      "16: 12795 \n",
      "17: 9414 \n",
      "18: 6640 \n",
      "19: 4729 \n",
      "20: 3560 \n",
      "21: 2608 \n",
      "22: 1913 \n",
      "23: 1420 \n",
      "24: 1025 \n",
      "25: 728 \n",
      "26: 442 \n",
      "27: 285 \n",
      "28: 205 \n",
      "29: 159 \n",
      "30: 120 \n",
      "31: 94 \n",
      "32: 68 \n",
      "33: 42 \n",
      "34: 41 \n",
      "35: 37 \n",
      "36: 40 \n",
      "37: 25 \n",
      "38: 16 \n",
      "39: 13 \n",
      "40: 16 \n",
      "41: 10 \n",
      "42: 13 \n",
      "43: 8 \n",
      "44: 5 \n",
      "45: 8 \n",
      "46: 5 \n",
      "47: 8 \n",
      "48: 2 \n",
      "49: 3 \n",
      "50: 6 \n",
      "51: 3 \n",
      "52: 5 \n",
      "53: 3 \n",
      "55: 1 \n",
      "56: 4 \n",
      "57: 3 \n",
      "58: 2 \n",
      "61: 5 \n",
      "62: 1 \n",
      "63: 2 \n",
      "64: 1 \n",
      "65: 1 \n",
      "66: 2 \n",
      "67: 2 \n",
      "68: 3 \n",
      "69: 1 \n",
      "71: 1 \n",
      "72: 2 \n",
      "76: 2 \n",
      "77: 1 \n",
      "78: 1 \n",
      "79: 1 \n",
      "84: 1 \n",
      "85: 2 \n",
      "86: 1 \n",
      "88: 2 \n",
      "89: 1 \n",
      "91: 1 \n",
      "93: 3 \n",
      "95: 1 \n",
      "119: 1 \n",
      "127: 2 \n",
      "128: 1 \n",
      "132: 1 \n",
      "137: 1 \n",
      "140: 1 \n",
      "142: 1 \n",
      "151: 2 \n",
      "159: 1 \n",
      "221: 1 \n",
      "249: 1 \n",
      "261: 1 \n",
      "372: 1 \n",
      "393: 1 \n",
      "409: 1 \n",
      "442: 1 \n",
      "455: 1 \n",
      "471: 1 \n",
      "474: 2 \n",
      "482: 1 \n",
      "585: 1 \n",
      "613: 1 \n",
      "719: 1 \n",
      "741: 1 \n",
      "746: 1 \n",
      "777: 1 \n",
      "873: 1 \n",
      "1059: 1 \n",
      "1298: 1 \n",
      "1484: 1 \n",
      "1688: 1 \n"
     ]
    }
   ],
   "source": [
    "deleted_words = []\n",
    "\n",
    "counter_word_length = Counter()\n",
    "for w in word_counter_lower:\n",
    "    counter_word_length[len(w)] += 1\n",
    "    if len(w) >= 30:\n",
    "        deleted_words.append(w)\n",
    "        # print(f\"{w} are {len(w)} chars\")\n",
    "\n",
    "for w in deleted_words:\n",
    "    del word_counter_lower[w]\n",
    "        \n",
    "for w,c in sorted(counter_word_length.items()):\n",
    "    print(f\"{w}: {c} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de: 2797452\n",
      "în: 1698624\n",
      "și: 1495074\n",
      "a: 1493621\n",
      "din: 998109\n",
      "la: 821174\n",
      "este: 681480\n",
      "o: 664635\n",
      "cu: 589335\n",
      "un: 497759\n",
      "fost: 495226\n",
      "care: 467471\n",
      "pe: 447799\n",
      "al: 380862\n",
      "mai: 346513\n",
      "se: 327611\n",
      "În: 327210\n",
      "pentru: 314924\n",
      "au: 273250\n",
      "să: 260212\n"
     ]
    }
   ],
   "source": [
    "# most common case insensitive words\n",
    "\n",
    "for k,v in word_counter.most_common(20):\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de: 2834895\n",
      "în: 2026031\n",
      "a: 1603371\n",
      "și: 1499422\n",
      "din: 1041139\n",
      "la: 903952\n",
      "este: 721009\n",
      "o: 688487\n",
      "cu: 609841\n",
      "un: 517270\n",
      "fost: 495386\n",
      "pe: 482019\n",
      "care: 467837\n",
      "al: 387148\n",
      "mai: 358593\n",
      "pentru: 349476\n",
      "se: 347172\n",
      "au: 281314\n",
      "să: 261160\n",
      "lui: 219195\n"
     ]
    }
   ],
   "source": [
    "# most common case sensitive words\n",
    "\n",
    "for k,v in word_counter_lower.most_common(20):\n",
    "    print(f\"{k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the input I would like to correct\n",
    "\n",
    "input_text = \"Ambasadorul SUA la Natiunile Unite, Nikky Haley, a declarat miercuri ca Statele Unite considera ca Rusia este responsabila pentru atacul chimic din Marea Britanie asupra fostului spion rus si a fiicei sale. De asemenea, Consiliul de Securitate al ONU ar trebui sa ia masuri, mai spune aceasta, potrivit reuters.com.Premierul britaqnic Theresa May a anuntat, intr-un discurs tinut in parlament, ca va expulza 23 de diplomati rusi. May a adaugat ca este cel mai masiv val de expulzari din ultimii peste 30 de ani. Ambasadorul Moscovei la Londra a avertizat ca vor exista masuri reciproce daca Regatul Unit expulzeaza diplomati rusi.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambasadorul SUA la Natiunile Unite, Nikky Haley, a declarat miercuri ca Statele Unite considera ca Rusia este responsabila pentru atacul chimic din Marea Britanie asupra fostului spion rus si a fiicei sale. De asemenea, Consiliul de Securitate al ONU ar trebui sa ia masuri, mai spune aceasta, potrivit reuters.com.Premierul britaqnic Theresa May a anuntat, intr-un discurs tinut in parlament, ca va expulza 23 de diplomati rusi. May a adaugat ca este cel mai masiv val de expulzari din ultimii peste 30 de ani. Ambasadorul Moscovei la Londra a avertizat ca vor exista masuri reciproce daca Regatul Unit expulzeaza diplomati rusi.\n"
     ]
    }
   ],
   "source": [
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter['acasă']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word_counter and word_counter_lower to picke files ( because they are expensive to generate)\n",
    "\n",
    "import pickle\n",
    "\n",
    "FILE_FOR_COUNTERS = join(DATA_PATH,'saved_counters.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_FOR_COUNTERS, 'wb') as dump_file:\n",
    "    pickle.dump([word_counter, word_counter_lower], dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( in case we need to) restore word_counter and word_counter_lower from files \n",
    "with open(FILE_FOR_COUNTERS, 'rb') as dump_file:\n",
    "    word_counter, word_counter_lower = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned counter\n",
    "with open('../data/pickle_clean_words_lower.pickle', 'rb') as dump_file:\n",
    "    word_counter_lower = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_misspellings(w):\n",
    "    \"\"\"Generate all miss-spellings of word w caused by missing diacritical marks\"\"\"\n",
    "    \n",
    "    specials = {'î':'i', 'ă':'a', 'ș':'s', 'ț':'t', 'î':'i', 'â':'a'}\n",
    "    specials = {'î':'i', 'ă':'a', 'ș':'s', 'ț':'t', 'î':'i', 'â':'a', '-':''}\n",
    "\n",
    "    spellings = [\"\"]\n",
    "    count_specials_found=0\n",
    "    pos=0\n",
    "    for l in w:\n",
    "#         print(l)\n",
    "        pos += 1\n",
    "        if l in specials:\n",
    "            count_specials_found +=1\n",
    "            if count_specials_found > 5:\n",
    "                print(f\"{w}: many specials: {count_specials_found}\")\n",
    "            if count_specials_found == 10:\n",
    "                print(f\"{w}: TOO many specials: {count_specials_found}\")\n",
    "                return spellings\n",
    "            spellings = [spelling + l for spelling in spellings]\n",
    "#             print(spellings)\n",
    "#             print(f\"adding: {[ tmp_s[0:-1] + specials[l] for tmp_s in spellings]}\")\n",
    "            spellings.extend( [ tmp_s[0:-1] + specials[l] for tmp_s in spellings])\n",
    "#             print(f\"new spelling {w[0:pos]}\")\n",
    "        else:\n",
    "            spellings = [spelling + l for spelling in spellings]\n",
    "#         print(spellings)\n",
    "#         print()\n",
    "    return spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['într-oî',\n",
       " 'intr-oî',\n",
       " 'întroî',\n",
       " 'introî',\n",
       " 'într-oi',\n",
       " 'intr-oi',\n",
       " 'întroi',\n",
       " 'introi']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "încăpățânată: many specials: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['încăpățânată',\n",
       " 'incăpățânată',\n",
       " 'încapățânată',\n",
       " 'incapățânată',\n",
       " 'încăpațânată',\n",
       " 'incăpațânată',\n",
       " 'încapațânată',\n",
       " 'incapațânată',\n",
       " 'încăpătânată',\n",
       " 'incăpătânată',\n",
       " 'încapătânată',\n",
       " 'incapătânată',\n",
       " 'încăpatânată',\n",
       " 'incăpatânată',\n",
       " 'încapatânată',\n",
       " 'incapatânată',\n",
       " 'încăpățanată',\n",
       " 'incăpățanată',\n",
       " 'încapățanată',\n",
       " 'incapățanată',\n",
       " 'încăpațanată',\n",
       " 'incăpațanată',\n",
       " 'încapațanată',\n",
       " 'incapațanată',\n",
       " 'încăpătanată',\n",
       " 'incăpătanată',\n",
       " 'încapătanată',\n",
       " 'incapătanată',\n",
       " 'încăpatanată',\n",
       " 'incăpatanată',\n",
       " 'încapatanată',\n",
       " 'incapatanată',\n",
       " 'încăpățânata',\n",
       " 'incăpățânata',\n",
       " 'încapățânata',\n",
       " 'incapățânata',\n",
       " 'încăpațânata',\n",
       " 'incăpațânata',\n",
       " 'încapațânata',\n",
       " 'incapațânata',\n",
       " 'încăpătânata',\n",
       " 'incăpătânata',\n",
       " 'încapătânata',\n",
       " 'incapătânata',\n",
       " 'încăpatânata',\n",
       " 'incăpatânata',\n",
       " 'încapatânata',\n",
       " 'incapatânata',\n",
       " 'încăpățanata',\n",
       " 'incăpățanata',\n",
       " 'încapățanata',\n",
       " 'incapățanata',\n",
       " 'încăpațanata',\n",
       " 'incăpațanata',\n",
       " 'încapațanata',\n",
       " 'incapațanata',\n",
       " 'încăpătanata',\n",
       " 'incăpătanata',\n",
       " 'încapătanata',\n",
       " 'incapătanata',\n",
       " 'încăpatanata',\n",
       " 'incăpatanata',\n",
       " 'încapatanata',\n",
       " 'incapatanata']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate_misspellings(\"îpârâu\")\n",
    "generate_misspellings(\"într-oî\")\n",
    "generate_misspellings(\"încăpățânată\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "căpșuniță-roșie: many specials: 6\n",
      "îmbrățișându-le: many specials: 6\n",
      "căzăneștiandrășești: many specials: 6\n",
      "încăpățânată: many specials: 6\n",
      "împărăteasa-văduvă: many specials: 6\n",
      "încăpățânați: many specials: 6\n",
      "înfățișându-i: many specials: 6\n",
      "căpățâneni-pământeni: many specials: 6\n",
      "căpățâneni-pământeni: many specials: 7\n",
      "săvârșește-ți: many specials: 6\n",
      "învățământ-cultură: many specials: 6\n",
      "învățământ-cultură: many specials: 7\n",
      "buzău-mărășești: many specials: 6\n",
      "muncitorești-țărănești: many specials: 6\n",
      "înfățișându-l: many specials: 6\n",
      "împărăteasă-mamă: many specials: 6\n",
      "împărtășindu-și: many specials: 6\n",
      "mănăstire-reședință: many specials: 6\n",
      "încăpățânează: many specials: 6\n",
      "moșnenească-țărănească: many specials: 6\n",
      "moșnenească-țărănească: many specials: 7\n",
      "împărăteasă-regentă: many specials: 6\n",
      "lăscuț-făgărășanu: many specials: 6\n",
      "lăscuț-făgărășanu: many specials: 7\n",
      "păușești-măglași: many specials: 6\n",
      "îmbrățișând-o: many specials: 6\n",
      "îmbrățișându-se: many specials: 6\n",
      "îmbrățișându-i: many specials: 6\n",
      "încăpățânării: many specials: 6\n",
      "învățându-mă: many specials: 6\n",
      "rădulești-căldărușani: many specials: 6\n",
      "înălțându-și: many specials: 6\n",
      "măgurelepăcurețibălțești: many specials: 6\n",
      "îmbunătățindu-ți: many specials: 6\n",
      "învățându-și: many specials: 6\n",
      "ceaușești-ștefănești: many specials: 6\n",
      "târâș-grăpiș: many specials: 6\n",
      "mânzălești-mănești: many specials: 6\n",
      "săptămână-două: many specials: 6\n",
      "drăgăești-pământeni: many specials: 6\n",
      "păișești-măglași: many specials: 6\n",
      "păușești-olănești: many specials: 6\n",
      "ștefăniță-vodă: many specials: 6\n",
      "miroslăvești-năvrăpești: many specials: 6\n",
      "gălăuțaș-pârău: many specials: 6\n",
      "gălăuțaș-pârău: many specials: 7\n",
      "ștefănești-lipovățul: many specials: 6\n",
      "șorț-cătrință: many specials: 6\n",
      "înfățișându-ne: many specials: 6\n",
      "răcătău-răzeși: many specials: 6\n",
      "creșă-grădiniță: many specials: 6\n",
      "grădiniță-creșă: many specials: 6\n",
      "perșano-făgărășene: many specials: 6\n",
      "tăuții-măgherăuș: many specials: 6\n",
      "păușești-otăsău: many specials: 6\n",
      "național-țărăniști: many specials: 6\n",
      "național-țărănistă: many specials: 6\n",
      "național-țărăniștilor: many specials: 6\n",
      "național-țărăniștii: many specials: 6\n",
      "argeș-transfăgărășan: many specials: 6\n",
      "învățământ-seminarul: many specials: 6\n",
      "târnăveni-bălăușeri: many specials: 6\n",
      "îmbrăcăminte-încălțăminte: many specials: 6\n",
      "îmbrăcăminte-încălțăminte: many specials: 7\n",
      "îmbrăcăminte-încălțăminte: many specials: 8\n",
      "călăreți-arnăuți: many specials: 6\n",
      "îmbrățișându-și: many specials: 6\n",
      "îmbrățișându-și: many specials: 7\n",
      "săvârșiți-vă: many specials: 6\n",
      "înfățișându-se: many specials: 6\n",
      "mânăstirii-fortăreață: many specials: 6\n",
      "predată-învățată: many specials: 6\n",
      "învățământ-știință: many specials: 6\n",
      "învățământ-știință: many specials: 7\n",
      "învățământ-știință: many specials: 8\n",
      "învățământ-știință: many specials: 9\n",
      "moșteni-călărășani: many specials: 6\n",
      "fărcășești-moșneni: many specials: 6\n",
      "înălțime-lățime: many specials: 6\n",
      "târâș-grăbiș: many specials: 6\n",
      "încăpățânăm: many specials: 6\n",
      "boiștea-răzășească: many specials: 6\n",
      "sălaj-șărmășag: many specials: 6\n",
      "milișăuți-bădeuți: many specials: 6\n",
      "înfășurați-mă: many specials: 6\n",
      "înfățișând-o: many specials: 6\n",
      "cântăreață-actriță: many specials: 6\n",
      "cântăreață-actriță: many specials: 7\n",
      "cântăreața-actriță: many specials: 6\n",
      "drăguș-făgăraș: many specials: 6\n",
      "neîmpărtășindu-și: many specials: 6\n",
      "școală-grădiniță: many specials: 6\n",
      "doctoriță-călugăriță: many specials: 6\n",
      "doctoriță-călugăriță: many specials: 7\n",
      "mărișel-lăpuștești: many specials: 6\n",
      "băleștilor-răzășie: many specials: 6\n",
      "bărtăluș-răzeși: many specials: 6\n",
      "tăcmănești-răzeși: many specials: 6\n",
      "ciofeni-cănțălărești: many specials: 6\n",
      "rădăuțiștefănești: many specials: 6\n",
      "disfuncționalități-priorități: many specials: 6\n",
      "încăpățânându-se: many specials: 6\n",
      "încăpățânându-se: many specials: 7\n",
      "încărcării-descărcării: many specials: 6\n",
      "cârtiță-rață: many specials: 6\n",
      "ștefănescu-mățău: many specials: 6\n",
      "înștiințându-mă: many specials: 6\n",
      "îngemănatăîmbrățișată: many specials: 6\n",
      "îngemănatăîmbrățișată: many specials: 7\n",
      "îngemănatăîmbrățișată: many specials: 8\n",
      "îmbunătățindu-și: many specials: 6\n",
      "învățând-și: many specials: 6\n",
      "țigănușul-bătrân: many specials: 6\n",
      "otomană—înstrăinându-și: many specials: 6\n",
      "vășcăuți-mușenița: many specials: 6\n",
      "vășcăuți-mușenița: many specials: 7\n",
      "oreșaț-vârșeț: many specials: 6\n",
      "bănățeană-hunedoreană: many specials: 6\n",
      "călugărcălugăriță: many specials: 6\n",
      "înțepătură-țintuită: many specials: 6\n",
      "înțepătură-țintuită: many specials: 7\n",
      "măicuțe-dăscălițe: many specials: 6\n",
      "repare-îmbunătățească: many specials: 6\n",
      "învățaților-birocrați: many specials: 6\n",
      "săptămânălângă: many specials: 6\n",
      "cătămărăști-vale: many specials: 6\n",
      "învățaților-religioși: many specials: 6\n",
      "dărăști-mărcuța: many specials: 6\n",
      "cămărășescu-oteteleșanu: many specials: 6\n",
      "împărțirerădăcină: many specials: 6\n",
      "vătășoiu-liță: many specials: 6\n",
      "mărăști-mărășești: many specials: 6\n",
      "mărăști-mărășești: many specials: 7\n",
      "mărăști-mărășești: many specials: 8\n",
      "bucurești-mărășești: many specials: 6\n",
      "îmbărbătându-și: many specials: 6\n",
      "câtcâtăcâțicâte: many specials: 6\n",
      "țărănești-tradiționale: many specials: 6\n",
      "înfășură-ntreagă: many specials: 6\n",
      "fumărică-bășicoasă: many specials: 6\n",
      "înălțându-ți: many specials: 6\n",
      "înfățișându-le: many specials: 6\n",
      "mănăstire-fortăreață: many specials: 6\n",
      "învățămâțntului: many specials: 6\n",
      "cântăreață-interpretă: many specials: 6\n",
      "rădăcină-sălbatică: many specials: 6\n",
      "îmbrățișându-l: many specials: 6\n",
      "cultură-învățământ: many specials: 6\n",
      "cultură-învățământ: many specials: 7\n",
      "actrița-cântăreață: many specials: 6\n",
      "sâmbătă-dimineață: many specials: 6\n",
      "țărăniștii-democrați: many specials: 6\n",
      "mănăstirea-fortăreață: many specials: 6\n",
      "hutorî-krîvoșîiinețki: many specials: 6\n",
      "lătărețu-bosâncă: many specials: 6\n",
      "înfățișându-ți: many specials: 6\n",
      "înfățișându-ți: many specials: 7\n",
      "căpățână-juller: many specials: 6\n",
      "formare-învățământ: many specials: 6\n",
      "actrițăcântăreață: many specials: 6\n",
      "învățători-ofițeri: many specials: 6\n"
     ]
    }
   ],
   "source": [
    "spellings_lower = defaultdict(Counter)\n",
    "\n",
    "for word, counter in word_counter_lower.items():\n",
    "    misspellings = generate_misspellings(word)\n",
    "#     print(f\"{word}: {len(misspellings)}\")\n",
    "#     print(misspellings)\n",
    "    for misspelling in misspellings:\n",
    "        spellings_lower[misspelling][word] = counter\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'acasa': 121, 'acasă': 4458})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'parau': 36,\n",
       "         'pârau': 2,\n",
       "         'pârâu': 275,\n",
       "         'pârău': 13,\n",
       "         'părau': 1,\n",
       "         'părâu': 1,\n",
       "         'părău': 59})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'in-tro': 1,\n",
       "         'intr-o': 621,\n",
       "         'intro': 71,\n",
       "         'în-tro': 4,\n",
       "         'într-o': 37987,\n",
       "         'întro': 37})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'incapatanata': 1,\n",
       "         'incăpățânată': 2,\n",
       "         'încăpățânata': 1,\n",
       "         'încăpățânată': 27})"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellings_lower['acasa']\n",
    "spellings_lower['parau']\n",
    "spellings_lower['intro']\n",
    "spellings_lower['incapatanata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spellings_lower to pickle file so we ca use it later\n",
    "\n",
    "# DATA_PATH = \"../data/\"\n",
    "with open(join(DATA_PATH,'rowiki_spellings.pickle'), 'wb') as pickle_file:\n",
    "    pickle.dump( spellings_lower, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7039"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter_lower[\"unit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'acasa': 113, 'acasă': 3934})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'parau': 20,\n",
       "         'pârau': 2,\n",
       "         'pârâu': 255,\n",
       "         'pârău': 13,\n",
       "         'părau': 1,\n",
       "         'părâu': 1,\n",
       "         'părău': 55})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'in-tro': 1,\n",
       "         'intr-o': 577,\n",
       "         'intro': 63,\n",
       "         'în-tro': 4,\n",
       "         'într-o': 33569,\n",
       "         'întro': 33})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellings_lower['acasa']\n",
    "spellings_lower['parau']\n",
    "spellings_lower['intro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1367905"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spellings_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(word) for word in spellings_lower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apomnemomneumata-memorabilele\n",
      "nowikinowikirăpitnowikinowiki\n",
      "nowikinowikirapitnowikinowiki\n",
      "kurfürstlich-brandenburgische\n",
      "raionuluimunicipiuluiunității\n",
      "raionuluimunicipiuluiunitații\n",
      "raionuluimunicipiuluiunitătii\n",
      "raionuluimunicipiuluiunitatii\n",
      "romulusbărbulescugeorgeanania\n",
      "romulusbarbulescugeorgeanania\n",
      "richmondfredericksburgpotomac\n",
      "perhidrociclopentanofenantren\n",
      "monarhiști-constituționaliști\n",
      "monarhisti-constituționaliști\n",
      "monarhiști-constitutionaliști\n",
      "monarhisti-constitutionaliști\n",
      "monarhiști-constituționalisti\n",
      "monarhisti-constituționalisti\n",
      "monarhiști-constitutionalisti\n",
      "monarhisti-constitutionalisti\n",
      "fessanvilliers-mattanvilliers\n",
      "ampaacrealaudiorealvideompeg4\n",
      "autotohtonist-tradiționalistă\n",
      "autotohtonist-traditionalistă\n",
      "autotohtonist-tradiționalista\n",
      "autotohtonist-traditionalista\n",
      "continuitateadiscontinuitatea\n",
      "ftaliltetrahidroizochinolinic\n",
      "nominativacuzativdativgenitiv\n",
      "bucureștioradeabudapestaviena\n",
      "bucurestioradeabudapestaviena\n",
      "strigoniensis-budapestinensis\n",
      "pestszentlőrinc-pestszentimre\n",
      "bezbednostisigurnostivarnosti\n",
      "ciclopentanperhidrofentrenică\n",
      "ciclopentanperhidrofentrenica\n",
      "rotextemonumentecercetareajoc\n",
      "bezirksverordnetenversammlung\n",
      "disfuncționalități-priorități\n",
      "disfunctionalități-priorități\n",
      "disfuncționalitați-priorități\n",
      "disfunctionalitați-priorități\n",
      "disfuncționalităti-priorități\n",
      "disfunctionalităti-priorități\n",
      "disfuncționalitati-priorități\n",
      "disfunctionalitati-priorități\n",
      "disfuncționalități-prioritați\n",
      "disfunctionalități-prioritați\n",
      "disfuncționalitați-prioritați\n",
      "disfunctionalitați-prioritați\n",
      "disfuncționalităti-prioritați\n",
      "disfunctionalităti-prioritați\n",
      "disfuncționalitati-prioritați\n",
      "disfunctionalitati-prioritați\n",
      "disfuncționalități-priorităti\n",
      "disfunctionalități-priorităti\n",
      "disfuncționalitați-priorităti\n",
      "disfunctionalitați-priorităti\n",
      "disfuncționalităti-priorităti\n",
      "disfunctionalităti-priorităti\n",
      "disfuncționalitati-priorităti\n",
      "disfunctionalitati-priorităti\n",
      "disfuncționalități-prioritati\n",
      "disfunctionalități-prioritati\n",
      "disfuncționalitați-prioritati\n",
      "disfunctionalitați-prioritati\n",
      "disfuncționalităti-prioritati\n",
      "disfunctionalităti-prioritati\n",
      "disfuncționalitati-prioritati\n",
      "disfunctionalitati-prioritati\n",
      "achiziționareacedareacesiunea\n",
      "achizitionareacedareacesiunea\n",
      "internationaleneoliberalismul\n",
      "fluorchlorkohlenwasserstoffen\n",
      "erziehungsdirektorenkonferenz\n",
      "tiraspoltransgaz-pridnestrove\n",
      "kölneuskirchengerolsteintrier\n",
      "oxihemoglobinăoxihemoglobinat\n",
      "oxihemoglobinaoxihemoglobinat\n",
      "reichsdeputationshauptschluss\n",
      "abstracționismul-impresionist\n",
      "abstractionismul-impresionist\n",
      "actualilorfoștilorposibililor\n",
      "actualilorfostilorposibililor\n",
      "administrativ-jurisdicțională\n",
      "administrativ-jurisdictională\n",
      "administrativ-jurisdicționala\n",
      "administrativ-jurisdictionala\n",
      "ansamblurilorsubansamblurilor\n",
      "constructivistconstructionist\n",
      "antidisestablishmentarianisms\n",
      "socialeparticipativefeministe\n",
      "ss-unterschutzhaftlagerführer\n",
      "trimethoprim-sulfamethoxazole\n"
     ]
    }
   ],
   "source": [
    "for word in spellings_lower:\n",
    "    if len(word) == 29:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambasadorul: 642 642 Counter({'ambasadorul': 642})\n",
      "sua: 9217 9217 Counter({'sua': 9217, 's-ua': 2})\n",
      "la: 903952 903952 Counter({'la': 903952, 'l-a': 26936, 'lă': 4, 'lâ': 1})\n",
      "natiunile: 6 6 Counter({'națiunile': 468, 'natiunile': 6})\n",
      "unite: 21615 21615 Counter({'unite': 21615, 'u-nite': 4})\n",
      "nikky: 3 3 Counter({'nikky': 3})\n",
      "haley: 52 52 Counter({'haley': 52})\n",
      "a: 1603371 1603371 Counter({'a': 1603371, 'ă': 282, 'â': 149})\n",
      "declarat: 9177 9177 Counter({'declarat': 9177})\n",
      "miercuri: 222 222 Counter({'miercuri': 222})\n",
      "ca: 207063 207063 Counter({'ca': 207063, 'că': 175083, 'câ': 23, 'c-a': 11})\n",
      "statele: 16591 16591 Counter({'statele': 16591, 'ștatele': 3})\n",
      "unite: 21615 21615 Counter({'unite': 21615, 'u-nite': 4})\n",
      "considera: 2744 2744 Counter({'consideră': 5870, 'considera': 2744})\n",
      "ca: 207063 207063 Counter({'ca': 207063, 'că': 175083, 'câ': 23, 'c-a': 11})\n",
      "rusia: 9214 9214 Counter({'rusia': 9214})\n",
      "este: 721009 721009 Counter({'este': 721009, 'ește': 3})\n",
      "responsabila: 16 16 Counter({'responsabilă': 573, 'responsabila': 16})\n",
      "pentru: 349476 349476 Counter({'pentru': 349476, 'pen-tru': 2})\n",
      "atacul: 2736 2736 Counter({'atacul': 2736})\n",
      "chimic: 1024 1024 Counter({'chimic': 1024})\n",
      "din: 1041139 1041139 Counter({'din': 1041139, 'dîn': 16})\n",
      "marea: 15245 15245 Counter({'marea': 15245, 'mărea': 17})\n",
      "britanie: 4990 4990 Counter({'britanie': 4990})\n",
      "asupra: 27235 27235 Counter({'asupra': 27235, 'asupră': 4})\n",
      "fostului: 1958 1958 Counter({'fostului': 1958})\n",
      "spion: 257 257 Counter({'spion': 257})\n",
      "rus: 5480 5480 Counter({'rus': 5480, 'ruș': 4})\n",
      "si: 30845 30845 Counter({'și': 1499422, 'si': 30845, 'șî': 40, 'sî': 8, 'ș-i': 2, 's-i': 1})\n",
      "a: 1603371 1603371 Counter({'a': 1603371, 'ă': 282, 'â': 149})\n",
      "fiicei: 843 843 Counter({'fiicei': 843})\n",
      "sale: 49539 49539 Counter({'sale': 49539, 'șale': 4, 'săle': 3, 'să-le': 2, 'ș-ale': 1})\n",
      "de: 2834895 2834895 Counter({'de': 2834895})\n",
      "asemenea: 38994 38994 Counter({'asemenea': 38994})\n",
      "consiliul: 8523 8523 Counter({'consiliul': 8523})\n",
      "de: 2834895 2834895 Counter({'de': 2834895})\n",
      "securitate: 3036 3036 Counter({'securitate': 3036})\n",
      "al: 387148 387148 Counter({'al': 387148, 'a-l': 4189, 'ăl': 18, 'âl': 1})\n",
      "onu: 1449 1449 Counter({'onu': 1449})\n",
      "ar: 45280 45280 Counter({'ar': 45280, 'ăr': 2, 'a-r': 2})\n",
      "trebui: 3289 3289 Counter({'trebui': 3289})\n",
      "sa: 68851 68851 Counter({'să': 261160, 's-a': 126449, 'sa': 68851, 'șa': 97, 'șă': 36, 'ș-a': 26, 'sâ': 17, 's-ă': 6})\n",
      "ia: 6442 6442 Counter({'i-a': 24283, 'ia': 6442, 'î-a': 4, 'îâ': 2, 'îa': 2, 'îă': 1})\n",
      "masuri: 32 32 Counter({'măsuri': 2237, 'masuri': 32})\n",
      "mai: 358593 358593 Counter({'mai': 358593, 'm-ai': 62, 'măi': 43, 'ma-i': 10})\n",
      "spune: 9091 9091 Counter({'spune': 9091})\n",
      "aceasta: 28468 28468 Counter({'această': 54111, 'aceasta': 28468, 'aceastâ': 4, 'aceasță': 3, 'aceas-tă': 3})\n",
      "potrivit: 7339 7339 Counter({'potrivit': 7339})\n",
      "reuters: 71 71 Counter({'reuters': 71})\n",
      "com: 1220 1220 Counter({'com': 1220})\n",
      "premierul: 563 563 Counter({'premierul': 563})\n",
      "britaqnic: 0 0 Counter()\n",
      "theresa: 182 182 Counter({'theresa': 182})\n",
      "may: 697 697 Counter({'may': 697})\n",
      "a: 1603371 1603371 Counter({'a': 1603371, 'ă': 282, 'â': 149})\n",
      "anuntat: 100 100 Counter({'anunțat': 5386, 'anuntat': 100})\n",
      "intr-un: 574 574 Counter({'într-un': 30207, 'intr-un': 574})\n",
      "discurs: 1034 1034 Counter({'discurs': 1034})\n",
      "tinut: 60 60 Counter({'ținut': 3612, 'tinut': 60})\n",
      "in: 43583 43583 Counter({'în': 2026031, 'in': 43583})\n",
      "parlament: 2088 2088 Counter({'parlament': 2088})\n",
      "ca: 207063 207063 Counter({'ca': 207063, 'că': 175083, 'câ': 23, 'c-a': 11})\n",
      "va: 41839 41839 Counter({'va': 41839, 'vă': 1176, 'v-a': 524, 'vâ': 1})\n",
      "expulza: 26 26 Counter({'expulza': 26})\n",
      "23: 0 0 Counter()\n",
      "de: 2834895 2834895 Counter({'de': 2834895})\n",
      "diplomati: 1 1 Counter({'diplomați': 147, 'diplomati': 1})\n",
      "rusi: 42 42 Counter({'ruși': 3002, 'rusi': 42})\n",
      "may: 697 697 Counter({'may': 697})\n",
      "a: 1603371 1603371 Counter({'a': 1603371, 'ă': 282, 'â': 149})\n",
      "adaugat: 78 78 Counter({'adăugat': 2351, 'adaugat': 78, 'adâugat': 1})\n",
      "ca: 207063 207063 Counter({'ca': 207063, 'că': 175083, 'câ': 23, 'c-a': 11})\n",
      "este: 721009 721009 Counter({'este': 721009, 'ește': 3})\n",
      "cel: 78570 78570 Counter({'cel': 78570, 'ce-l': 456})\n",
      "mai: 358593 358593 Counter({'mai': 358593, 'm-ai': 62, 'măi': 43, 'ma-i': 10})\n",
      "masiv: 1259 1259 Counter({'masiv': 1259, 'mașiv': 2})\n",
      "val: 1459 1459 Counter({'val': 1459, 'văl': 89, 'v-al': 1})\n",
      "de: 2834895 2834895 Counter({'de': 2834895})\n",
      "expulzari: 0 0 Counter({'expulzări': 21})\n",
      "din: 1041139 1041139 Counter({'din': 1041139, 'dîn': 16})\n",
      "ultimii: 3583 3583 Counter({'ultimii': 3583})\n",
      "peste: 30245 30245 Counter({'peste': 30245, 'pește': 1225})\n",
      "30: 0 0 Counter()\n",
      "de: 2834895 2834895 Counter({'de': 2834895})\n",
      "ani: 68754 68754 Counter({'ani': 68754, 'âni': 2})\n",
      "ambasadorul: 642 642 Counter({'ambasadorul': 642})\n",
      "moscovei: 846 846 Counter({'moscovei': 846})\n",
      "la: 903952 903952 Counter({'la': 903952, 'l-a': 26936, 'lă': 4, 'lâ': 1})\n",
      "londra: 6458 6458 Counter({'londra': 6458, 'londră': 10})\n",
      "a: 1603371 1603371 Counter({'a': 1603371, 'ă': 282, 'â': 149})\n",
      "avertizat: 285 285 Counter({'avertizat': 285})\n",
      "ca: 207063 207063 Counter({'ca': 207063, 'că': 175083, 'câ': 23, 'c-a': 11})\n",
      "vor: 14450 14450 Counter({'vor': 14450})\n",
      "exista: 4124 4124 Counter({'există': 26366, 'exista': 4124, 'existâ': 1})\n",
      "masuri: 32 32 Counter({'măsuri': 2237, 'masuri': 32})\n",
      "reciproce: 220 220 Counter({'reciproce': 220})\n",
      "daca: 774 774 Counter({'dacă': 25324, 'daca': 774, 'dăcă': 2, 'dăca': 1, 'dacâ': 1})\n",
      "regatul: 9145 9145 Counter({'regatul': 9145})\n",
      "unit: 7039 7039 Counter({'unit': 7039})\n",
      "expulzeaza: 1 1 Counter({'expulzează': 17, 'expulzeaza': 1})\n",
      "diplomati: 1 1 Counter({'diplomați': 147, 'diplomati': 1})\n",
      "rusi: 42 42 Counter({'ruși': 3002, 'rusi': 42})\n"
     ]
    }
   ],
   "source": [
    "for input_word in text_to_word_sequence(input_text.lower(), \n",
    "                                        filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                        lower=False):\n",
    "    print(f\"{input_word}: {word_counter_lower[input_word]} {word_counter_lower[input_word.lower()]} {spellings_lower[input_word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
